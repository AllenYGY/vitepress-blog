import{_ as t,c as a,a5 as o,o as r}from"./chunks/framework.CHhwEXkI.js";const u=JSON.parse('{"title":"Comment Filtering System","description":"","frontmatter":{"date":"2024-11-17T00:00:00.000Z","title":"Comment Filtering System","status":"UNFINISHED","author":["AllenYGY"],"tags":["NOTE"],"publish":true},"headers":[],"relativePath":"posts/Machine Learning/Project/Comment Filtering System.md","filePath":"posts/Machine Learning/Project/Comment Filtering System.md","lastUpdated":null}'),i={name:"posts/Machine Learning/Project/Comment Filtering System.md"};function n(l,e,s,d,h,c){return r(),a("div",null,e[0]||(e[0]=[o('<h1 id="comment-filtering-system" tabindex="-1">Comment Filtering System <a class="header-anchor" href="#comment-filtering-system" aria-label="Permalink to &quot;Comment Filtering System&quot;">​</a></h1><h2 id="overview" tabindex="-1">overview <a class="header-anchor" href="#overview" aria-label="Permalink to &quot;overview&quot;">​</a></h2><p>我们的系统可以被分成两个部分，第一个部分是 illegal text detection, 第二个部分是高质量评论筛选 两个部分的模型分别训练</p><p>在上半部分，我们使用二分类的数据集对FastText模型和Bert 进行训练</p><p>在下半部分，我们通过筛选出的高质量评论对 Auto-Encoder 进行训练</p><p>最后我们的模型的运行效果应该是，当检测文本时，首先对文本进行敏感词识别，如果存在敏感词，那么就从上面走 如果没有识别到敏感词，就将文本输入Fasttext model, 进行第二次筛选，如果Fasttext 和 敏感词识别都呈现阳性 那么这个 text 会被判定成 非法文本</p><p>如果都识别成阴性，则会进入下游的模型进一步筛选 如果一阴一阳，那么又bert 做最后一次判断 决定其是否非法</p><p>进入下游的文本首先会经过bert 转成矩阵，训练好的 auto encoder 会尝试进行重建，如果重建误差在阈值范围内那就是高质量评论，反之亦然</p><h2 id="introduction" tabindex="-1">Introduction <a class="header-anchor" href="#introduction" aria-label="Permalink to &quot;Introduction&quot;">​</a></h2><h2 id="不文明用语过滤" tabindex="-1">不文明用语过滤 <a class="header-anchor" href="#不文明用语过滤" aria-label="Permalink to &quot;不文明用语过滤&quot;">​</a></h2><h3 id="数据集" tabindex="-1">数据集 <a class="header-anchor" href="#数据集" aria-label="Permalink to &quot;数据集&quot;">​</a></h3><h4 id="数据增强" tabindex="-1">数据增强 <a class="header-anchor" href="#数据增强" aria-label="Permalink to &quot;数据增强&quot;">​</a></h4><p>同音替换</p><h2 id="文本分类-ml-方法" tabindex="-1">文本分类 ML 方法 <a class="header-anchor" href="#文本分类-ml-方法" aria-label="Permalink to &quot;文本分类 ML 方法&quot;">​</a></h2><p>MultinomialNB RandomForest XGBoost LightGBM SVC ...</p><h2 id="文本分类-dl-方法" tabindex="-1">文本分类 DL 方法 <a class="header-anchor" href="#文本分类-dl-方法" aria-label="Permalink to &quot;文本分类 DL 方法&quot;">​</a></h2><p><strong>FastText</strong> TextCNN LSTM BERT</p><h2 id="模型选择" tabindex="-1">模型选择 <a class="header-anchor" href="#模型选择" aria-label="Permalink to &quot;模型选择&quot;">​</a></h2><p>最终选择 FastText 和 BERT 进行上游过滤</p><h2 id="高质量文本筛选" tabindex="-1">高质量文本筛选 <a class="header-anchor" href="#高质量文本筛选" aria-label="Permalink to &quot;高质量文本筛选&quot;">​</a></h2><p>假设高质量评论应该是高赞评论 通过将高赞评论输入到预训练语言模型BERT中进行特征提取，得到每个评论的矩阵表示</p><ul><li>基于我们的假设，高赞评论是高质量的评论，但是这并不意味着低赞评论就是低质量评论</li><li>比如有些评论的点赞量较少可能只是因为这条评论的曝光度不够</li><li>同时我们认为仅凭少量的人力人工筛选评论也是不现实且不客观的，毕竟高赞评论经历了大量人群的检验</li></ul><p>仅通过高赞的评论，学习高质量评论的特征 或许可以用Auto-Encoder来解决这个问题</p><h3 id="auto-encoder" tabindex="-1">Auto Encoder <a class="header-anchor" href="#auto-encoder" aria-label="Permalink to &quot;Auto Encoder&quot;">​</a></h3>',24)]))}const p=t(i,[["render",n]]);export{u as __pageData,p as default};

import{_ as o,c as l,a7 as a,j as e,a as i,o as n}from"./chunks/framework.Bfq_PhNx.js";const b=JSON.parse('{"title":"DV-03-Perception and Principles","description":"","frontmatter":{"date":"2025-12-29T00:00:00.000Z","title":"DV-03-Perception and Principles","status":"DONE","author":["AllenYGY"],"tags":["NOTE","DataVisualization"],"publish":true,"slidev":false},"headers":[],"relativePath":"posts/Data Analysis/Data Visualization/DV-03-Perception and Principles.md","filePath":"posts/Data Analysis/Data Visualization/DV-03-Perception and Principles.md","lastUpdated":null}'),s={name:"posts/Data Analysis/Data Visualization/DV-03-Perception and Principles.md"},r={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.262ex",height:"1.181ex",role:"img",focusable:"false",viewBox:"0 -511 1000 522","aria-hidden":"true"},p={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},h={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.262ex",height:"1.181ex",role:"img",focusable:"false",viewBox:"0 -511 1000 522","aria-hidden":"true"};function d(c,t,m,g,f,x){return n(),l("div",null,[t[11]||(t[11]=a('<hr><h1 id="dv-03-perception-and-principles" tabindex="-1">DV-03-Perception and Principles <a class="header-anchor" href="#dv-03-perception-and-principles" aria-label="Permalink to &quot;DV-03-Perception and Principles&quot;">​</a></h1><h2 id="visualization-process" tabindex="-1">Visualization Process <a class="header-anchor" href="#visualization-process" aria-label="Permalink to &quot;Visualization Process&quot;">​</a></h2><ul><li>Data Transformations</li><li>Visual mappings: mapping the ‘features’ of a dataset to the ‘features’ of visual perception.</li><li>Visual mapping</li></ul><hr><h3 id="bertin-s-semiology-of-graphics" tabindex="-1">Bertin’s Semiology of Graphics <a class="header-anchor" href="#bertin-s-semiology-of-graphics" aria-label="Permalink to &quot;Bertin’s Semiology of Graphics&quot;">​</a></h3><ul><li>Marks（标记）：点 / 线 / 面</li><li>Channels（视觉通道）： <ul><li>位置（x, y, z）</li><li>大小、形状</li><li>颜色（色相、亮度）</li><li>方向、纹理</li></ul></li><li>Data types： <ul><li>Nominal（名义）</li><li>Ordinal（有序）</li><li>Quantitative（定量)</li></ul></li></ul><h2 id="visual-attention" tabindex="-1">Visual Attention <a class="header-anchor" href="#visual-attention" aria-label="Permalink to &quot;Visual Attention&quot;">​</a></h2><ul><li><strong>自上而下 (Top-down)</strong>：有意识的努力，受认知驱动（例如在吵闹处读书）。</li><li><strong>自下而上 (Bottom-up)</strong>：无意识、自动触发，受外部刺激驱动（例如听到巨响转头）。</li><li><strong>改变盲视 (Change Blindness)</strong>：当注意力分散时，我们往往会漏掉场景中的巨大变化 。</li><li><strong>选择性注意 (Selective Attention)</strong>：著名的“大猩猩实验”证明：由于注意力资源有限，我们会忽略周围发生的很多事情</li></ul><h2 id="pre-attentive-processing" tabindex="-1">Pre attentive Processing <a class="header-anchor" href="#pre-attentive-processing" aria-label="Permalink to &quot;Pre attentive Processing&quot;">​</a></h2><p>The ability of the low-level human visual system to rapidly identify certain basic visual properties.</p>',11)),e("ul",null,[t[9]||(t[9]=a("<li><p>Without need for focused attention <em>不需要刻意思考</em></p></li><li><p>Tasks completed in less than 200 to 250 ms <em>&lt; 250ms</em></p></li><li><p>Parallel processing <em>并行处理</em></p></li><li><p><strong>前注意特征清单</strong>：</p><ul><li><strong>形状 (Form)</strong>：线段方向、长度、宽度、大小、弯曲度等。</li><li><strong>色彩 (Color)</strong>：色相 (Hue)、亮度 (Intensity)。</li><li><strong>其他</strong>：运动（闪烁、方向）、空间位置（2D 位置、立体深度）。</li></ul></li>",4)),e("li",null,[t[8]||(t[8]=e("p",null,[e("strong",null,"特征组合 (Feature Conjunction)"),i("："),e("strong",null,"非前注意加工"),i("。搜索同时具备两个特征（如“红色”且“圆形”）的对象需要顺序搜索，不能一眼识别。")],-1)),e("ul",null,[e("li",null,[t[2]||(t[2]=i("单一特征 ",-1)),e("mjx-container",r,[(n(),l("svg",u,[...t[0]||(t[0]=[e("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[e("g",{"data-mml-node":"math"},[e("g",{"data-mml-node":"mo"},[e("path",{"data-c":"2192",d:"M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z",style:{"stroke-width":"3"}})])])],-1)])])),t[1]||(t[1]=e("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("mo",{accent:"false",stretchy:"false"},"→")])],-1))]),t[3]||(t[3]=i(" 前注意",-1))]),e("li",null,[t[6]||(t[6]=i("特征组合（Feature Conjunction）",-1)),e("mjx-container",p,[(n(),l("svg",h,[...t[4]||(t[4]=[e("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[e("g",{"data-mml-node":"math"},[e("g",{"data-mml-node":"mo"},[e("path",{"data-c":"2192",d:"M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z",style:{"stroke-width":"3"}})])])],-1)])])),t[5]||(t[5]=e("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("mo",{accent:"false",stretchy:"false"},"→")])],-1))]),t[7]||(t[7]=i(" 非前注意",-1))])])]),t[10]||(t[10]=e("li",null,[e("p",null,[e("strong",null,"干扰 (Distraction)"),i("：干扰项越多或干扰项彼此差异越大，前注意特征的效果就越弱。 干扰与杂乱（Distraction & Clutter）")]),e("ul",null,[e("li",null,[i("两个判断“是否显眼”的因素： "),e("ol",null,[e("li",null,"目标 vs 干扰物 差异多大"),e("li",null,"干扰物之间 是否彼此相似")])])])],-1))]),t[12]||(t[12]=a('<h2 id="integral-vs-separable" tabindex="-1">Integral vs. Separable <a class="header-anchor" href="#integral-vs-separable" aria-label="Permalink to &quot;Integral vs. Separable&quot;">​</a></h2><ul><li>Separable（可分）= 可以同时、独立地看多个特征 <ul><li>位置 + 颜色（互不干扰）</li></ul></li><li>Integral（整体）= 多个特征会“黏在一起”被一起感知 <ul><li>宽 + 高、红 + 绿（会互相干扰）</li></ul></li></ul><p>Redundant coding: using separable dimensions to encode the same thing Interference: one visual attributes performance on the other</p><hr><ul><li>Many visual elements are preattentative <ul><li>Task dependent</li><li>Compound features can be non preattentative <ul><li>When highlighting, choose one feature only</li></ul></li></ul></li><li>To ensure that attention aligns with relevance in visuals used in visualization <ul><li>Goal: align the viewer&#39;s attention with the focus of the data.</li></ul></li></ul><hr><ul><li>A critical issue for information display is whether more complex patterns can be preattentively processed.</li><li>Coding with combinations of features requires <em>conjunction search</em></li><li>Guidelines for highlighting <ul><li>Adding marks to highlight is better than taking a mark away</li><li>Coding must stand out on some simple dimension <ul><li>Color &gt; simple shape = orientation, size</li></ul></li><li>Use whatever graphical dimension is least used elsewhere <ul><li>If the chart already uses a lot of colors, don&#39;t use color to highlight it.</li></ul></li></ul></li></ul><hr><p>Do not use pie chart because human Perception system are not good at estimate the different scales Magnitude</p><h2 id="gestalt-theory" tabindex="-1">Gestalt Theory <a class="header-anchor" href="#gestalt-theory" aria-label="Permalink to &quot;Gestalt Theory&quot;">​</a></h2><p>Gestalt theory explains how humans naturally organize visual elements into meaningful wholes.</p><p>People perceive patterns based on proximity, similarity, continuity, closure, symmetry, and figure–ground, which allows them to quickly interpret complex visual information as structured and coherent forms.</p><ul><li>Law of proximity <ul><li>Objects or shapes that are <strong>close</strong> to one another are perceived to form groups.</li></ul></li><li>Law of similarity <ul><li>Objects or shapes that are <strong>similar</strong> in shape, size, color, texture or value are perceived to belong together.</li></ul></li><li>Law of continuity <ul><li>Objects or shapes that are arranged in a line or a curve are perceived to be more related than those that are abrupt.</li></ul></li><li>Law of closure - Figures or shapes that are incomplete or partially hidden are perceived to be complete as our brain automatically fill in the gaps.</li><li>Law of symmetry <ul><li>Objects or shapes that are <strong>symmetrical</strong> and forming around a center point are {<strong>perceptually pleasing</strong>}.</li></ul></li><li>Law of figure-ground <ul><li>Humans can distinguish an object (the <strong>figure</strong> of the rule) from background (the <strong>ground</strong>)</li></ul></li></ul>',13))])}const w=o(s,[["render",d]]);export{b as __pageData,w as default};
//# sourceMappingURL=posts_Data Analysis_Data Visualization_DV-03-Perception and Principles.md.BGOLoKD6.js.map

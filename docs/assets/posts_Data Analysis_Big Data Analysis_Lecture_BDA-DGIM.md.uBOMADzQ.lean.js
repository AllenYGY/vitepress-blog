import{_ as t,c as i,a5 as s,o as a}from"./chunks/framework.CHhwEXkI.js";const p=JSON.parse('{"title":"BDA-DGIM","description":"","frontmatter":{"date":"2024-11-15T00:00:00.000Z","title":"BDA-DGIM","status":"DONE","author":["AllenYGY"],"tags":["NOTE","BDA"],"publish":true},"headers":[],"relativePath":"posts/Data Analysis/Big Data Analysis/Lecture/BDA-DGIM.md","filePath":"posts/Data Analysis/Big Data Analysis/Lecture/BDA-DGIM.md","lastUpdated":null}'),r={name:"posts/Data Analysis/Big Data Analysis/Lecture/BDA-DGIM.md"};function o(n,e,l,u,c,h){return a(),i("div",null,e[0]||(e[0]=[s('<h1 id="bda-dgim" tabindex="-1">BDA-DGIM <a class="header-anchor" href="#bda-dgim" aria-label="Permalink to &quot;BDA-DGIM&quot;">​</a></h1><p>Please describe the mechanism of DGIM. How the error bound is estimated? Is there a way to further reduce this error bound. Submit your response online within the allow time frame.</p><p><strong>Mechanism</strong></p><p>When a new bit comes in, drop the last (oldest) bucket if its end-time is prior to N time units before the current time.</p><p>2 cases: Current bit is 0 or 1 If the current bit is 0:</p><ul><li>no other changes are needed</li></ul><p>If the current bit is 1:</p><ul><li>Create a new bucket of size 1, for just this bit. <ul><li>End timestamp = current time</li></ul></li><li>If there are now three buckets of size 1, combine the oldest two into a bucket of size 2</li><li>If there are now three buckets of size 2, combine the oldest two into a bucket of size 4</li><li>And so on …</li></ul><p><strong>Solution</strong></p><p>To reduce the error bound in the DGIM algorithm, consider this:</p><p>Instead of maintaining 1 or 2 of each size bucket, we allow either r-1 or r buckets (r &gt; 2)</p><ul><li>Except for the largest size buckets; we can have any number between 1 and r of those</li></ul>',12)]))}const m=t(r,[["render",o]]);export{p as __pageData,m as default};

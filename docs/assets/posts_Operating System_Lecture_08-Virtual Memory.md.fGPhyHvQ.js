import{_ as a,c as l,a7 as i,o as t}from"./chunks/framework.Bfq_PhNx.js";const m=JSON.parse('{"title":"08-Virtual Memory","description":"","frontmatter":{"date":"2024-05-11T00:00:00.000Z","title":"08-Virtual Memory","status":"TOBECONTINUED","author":["AllenYGY"],"tags":["Lec8","OS","NOTE"],"publish":true},"headers":[],"relativePath":"posts/Operating System/Lecture/08-Virtual Memory.md","filePath":"posts/Operating System/Lecture/08-Virtual Memory.md","lastUpdated":null}'),o={name:"posts/Operating System/Lecture/08-Virtual Memory.md"};function r(n,e,s,c,h,u){return t(),l("div",null,[...e[0]||(e[0]=[i('<h1 id="virtual-memory" tabindex="-1">Virtual Memory <a class="header-anchor" href="#virtual-memory" aria-label="Permalink to &quot;Virtual Memory&quot;">​</a></h1><ul><li>Demand Paging</li><li>Copy-on-Write</li><li>Page Replacement</li><li>Allocation of Frames</li><li>Thrashing</li><li>Allocating Kernel Memory</li><li>Other Considerations</li></ul><h2 id="swapping" tabindex="-1">Swapping <a class="header-anchor" href="#swapping" aria-label="Permalink to &quot;Swapping&quot;">​</a></h2><h2 id="demand-paging" tabindex="-1">Demand Paging <a class="header-anchor" href="#demand-paging" aria-label="Permalink to &quot;Demand Paging&quot;">​</a></h2><p>Could bring a page into memory only when it is needed</p><p>Advantages:</p><ul><li>Less I/O needed</li><li>No unnecessary I/O</li><li>Less memory needed</li><li>Faster response</li><li>More users/processes</li></ul><h3 id="valid-invalid-bit" tabindex="-1">Valid-Invalid Bit <a class="header-anchor" href="#valid-invalid-bit" aria-label="Permalink to &quot;Valid-Invalid Bit&quot;">​</a></h3><h3 id="page-fault" tabindex="-1">Page Fault <a class="header-anchor" href="#page-fault" aria-label="Permalink to &quot;Page Fault&quot;">​</a></h3><h3 id="eat" tabindex="-1">EAT <a class="header-anchor" href="#eat" aria-label="Permalink to &quot;EAT&quot;">​</a></h3><h3 id="locality-reference-局部性原理" tabindex="-1">Locality Reference <code>局部性原理</code> <a class="header-anchor" href="#locality-reference-局部性原理" aria-label="Permalink to &quot;Locality Reference `局部性原理`&quot;">​</a></h3><h3 id="demand-paging-optimizations" tabindex="-1">Demand Paging Optimizations <a class="header-anchor" href="#demand-paging-optimizations" aria-label="Permalink to &quot;Demand Paging Optimizations&quot;">​</a></h3><h2 id="copy-on-write" tabindex="-1">Copy-on-Write <a class="header-anchor" href="#copy-on-write" aria-label="Permalink to &quot;Copy-on-Write&quot;">​</a></h2><h2 id="page-replacement" tabindex="-1">Page Replacement <a class="header-anchor" href="#page-replacement" aria-label="Permalink to &quot;Page Replacement&quot;">​</a></h2><h3 id="global-allocation" tabindex="-1">Global Allocation <a class="header-anchor" href="#global-allocation" aria-label="Permalink to &quot;Global Allocation&quot;">​</a></h3><h3 id="local-allocation" tabindex="-1">Local Allocation <a class="header-anchor" href="#local-allocation" aria-label="Permalink to &quot;Local Allocation&quot;">​</a></h3><h3 id="page-and-frame-replacement-algorithms" tabindex="-1">Page and Frame Replacement Algorithms <a class="header-anchor" href="#page-and-frame-replacement-algorithms" aria-label="Permalink to &quot;Page and Frame Replacement Algorithms&quot;">​</a></h3><ul><li>Frame-allocation algorithm determines <ul><li>How many frames to give each process</li></ul></li><li>Page-replacement algorithm <ul><li>Which frames to replace  Want lowest page-fault rate on both first access and re-access</li></ul></li></ul><h3 id="page-replacement-algorithms" tabindex="-1">Page Replacement Algorithms <a class="header-anchor" href="#page-replacement-algorithms" aria-label="Permalink to &quot;Page Replacement Algorithms&quot;">​</a></h3><ul><li>FIFO</li><li>Optimal</li><li>Least Recently Used (LRU)</li><li>Second chance</li><li>Enhanced second chance</li></ul><h4 id="fifo-algorithm" tabindex="-1">FIFO Algorithm <a class="header-anchor" href="#fifo-algorithm" aria-label="Permalink to &quot;FIFO Algorithm&quot;">​</a></h4><p>Rule</p><ul><li>Replace the oldest one</li></ul><p>Implementation</p><ul><li>OS maintains a circular queue of all pages <ul><li>Page at head of the list: Oldest one</li><li>Page at the tail: Recent arrival</li></ul></li><li>When there is a page fault <ul><li>Page at the head is removed</li><li>New page added to the tail</li></ul></li></ul><h5 id="belady-s-anomaly" tabindex="-1">Belady’s Anomaly <a class="header-anchor" href="#belady-s-anomaly" aria-label="Permalink to &quot;Belady’s Anomaly&quot;">​</a></h5><p>Belady’s Anomaly For some page-replacement algorithms, the page-fault rate may increase as the number of allocated frames increases.</p><p><strong>Adding more frames might cause more page faults!</strong></p><h4 id="optimal-algorithm" tabindex="-1">Optimal Algorithm <a class="header-anchor" href="#optimal-algorithm" aria-label="Permalink to &quot;Optimal Algorithm&quot;">​</a></h4><p>Replace the page that will not be used for longest period of reference string</p><p>Problem</p><ul><li>Can’t read the future This method can only be used to measure how other algorithms are close to the optimal</li></ul><h4 id="least-recently-used-lru-algorithm" tabindex="-1">Least Recently Used (LRU) Algorithm <a class="header-anchor" href="#least-recently-used-lru-algorithm" aria-label="Permalink to &quot;Least Recently Used (LRU) Algorithm&quot;">​</a></h4><p>Replace page that has not been used in the most amount of time</p><ul><li>LRU is a good algorithm and frequently used</li><li>LRU and OPT don’t have Belady’s Anomaly</li></ul><h5 id="counter-implementation" tabindex="-1">Counter Implementation <a class="header-anchor" href="#counter-implementation" aria-label="Permalink to &quot;Counter Implementation&quot;">​</a></h5><ul><li>There is a global counter that increases by 1 whenever a page is referenced. Every page in the memory has its own counter</li><li>When a page is referenced, its counter is synchronized with the global counter</li><li>When a page needs to be replaced, find the page in the memory with the smallest value</li></ul><p>Disadvantage</p><ul><li>Take O(n) time to search</li></ul><h5 id="stack-implementation" tabindex="-1">Stack Implementation <a class="header-anchor" href="#stack-implementation" aria-label="Permalink to &quot;Stack Implementation&quot;">​</a></h5><ul><li><p>Keep a stack of page numbers in a double link form:</p></li><li><p>When a page referenced:</p><ul><li>move it to the top</li><li>Advantage <ul><li>No search for replacement</li></ul></li><li>Disadvantage <ul><li>Each update of the stack might requires 6 pointers to be changed</li></ul></li></ul></li></ul><h4 id="lru-approximation-algorithms" tabindex="-1">LRU Approximation Algorithms <a class="header-anchor" href="#lru-approximation-algorithms" aria-label="Permalink to &quot;LRU Approximation Algorithms&quot;">​</a></h4><p>Usage of a reference bit</p><ul><li>Associate each page with a reference bit, initial value 0</li><li>When a page is referenced, set the bit 1</li><li>When a page is needed to be replaced, find the ones with reference bit 0 if exist one</li></ul><h5 id="second-chance-algorithm" tabindex="-1">Second-chance algorithm <a class="header-anchor" href="#second-chance-algorithm" aria-label="Permalink to &quot;Second-chance algorithm&quot;">​</a></h5><p>Second-chance algorithm</p><ul><li>Use a circular FIFO and reference bit for each page in memory</li><li>If page to be replaced has reference bit = 0 » replace it</li><li>reference bit = 1 » set reference bit to 0 » search for the next page</li></ul><h5 id="enhanced-second-chance-algorithm" tabindex="-1">Enhanced second-chance algorithm <a class="header-anchor" href="#enhanced-second-chance-algorithm" aria-label="Permalink to &quot;Enhanced second-chance algorithm&quot;">​</a></h5><p>Improve algorithm by using reference bit and modify bit for each page in memory</p><ul><li>i.e., an ordered pair (reference, modify)</li></ul><p>All pages in memory fall into four classes</p><ol><li>(0, 0) neither recently used not modified – best page to replace</li><li>(0, 1) not recently used but modified – not quite as good, must write out before replacement</li><li>(1, 0) recently used but clean – probably will be used again soon</li><li>(1, 1) recently used and modified – probably will be used again soon and need to write out before replacement – worst page to replace</li></ol><p>When page replacement called for, replace page in lowest nonempty class in clock scheme</p><ul><li>Disadvantage <ul><li>Might need to search circular queue several times</li></ul></li></ul><h3 id="page-buffering" tabindex="-1">Page Buffering <a class="header-anchor" href="#page-buffering" aria-label="Permalink to &quot;Page Buffering&quot;">​</a></h3><p>More strategies (algorithms) in improving the efficiency of page replacement</p><p>Page-buffering consideration</p><ul><li><p>Keep a pool of free frames always</p><ul><li>Whenever it is possible, select a victim to evict and add it to free pool</li><li>When convenient, evict the victim</li><li>When frame needed, read page into free frame</li><li>Advantage: Reduce time to find a free frame at a page fault</li></ul></li><li><p>Expansion</p><ul><li>Keep a list of modified pages <ul><li>Whenever the paging device is idle, write the modified page to the disk. Its modify bit is then reset to 0</li></ul></li><li>Keep free frame contents intact （完整的，内容未被清除的） <ul><li>Reduce penalty if wrong victim frame was selected</li><li>If the page is referenced again, no need to load from the disk</li></ul></li></ul></li></ul><h2 id="allocation-of-frames" tabindex="-1">Allocation of Frames <a class="header-anchor" href="#allocation-of-frames" aria-label="Permalink to &quot;Allocation of Frames&quot;">​</a></h2><p>For performance reason, each process needs minimum number of frames</p><h3 id="fixed-allocation" tabindex="-1">Fixed allocation <a class="header-anchor" href="#fixed-allocation" aria-label="Permalink to &quot;Fixed allocation&quot;">​</a></h3><h4 id="equal-allocation" tabindex="-1">Equal allocation <a class="header-anchor" href="#equal-allocation" aria-label="Permalink to &quot;Equal allocation&quot;">​</a></h4><ul><li>Each process is allocated same number of frames</li><li>Disadvantage <ul><li>Space waste for small process</li></ul></li></ul><h4 id="propositional-allocation" tabindex="-1">Propositional allocation <a class="header-anchor" href="#propositional-allocation" aria-label="Permalink to &quot;Propositional allocation&quot;">​</a></h4><ul><li>Allocate frames according to the size of a process</li><li>Disadvantage <ul><li>Process size might be changed during the execution</li></ul></li></ul><h4 id="priority-allocation" tabindex="-1">Priority allocation <a class="header-anchor" href="#priority-allocation" aria-label="Permalink to &quot;Priority allocation&quot;">​</a></h4><ul><li>the ratio of frames depends on the combination of size and priority of a process</li><li>Replace the pages of process with lower priority</li></ul><h2 id="thrashing-系统颠簸" tabindex="-1">Thrashing <code>系统颠簸</code> <a class="header-anchor" href="#thrashing-系统颠簸" aria-label="Permalink to &quot;Thrashing `系统颠簸`&quot;">​</a></h2><p>If a process does not have “enough” frames in memory, the page-fault rate is very high</p><ul><li>Replace page frequently</li><li>The replaced page might be used again</li><li>This leads to: <ul><li>Low CPU utilization</li><li>Operating system keeps adding new process, trying to increase CPU utilization</li><li>Things get worse -&gt; entering a bad cycle</li><li>Thrashing <ul><li>A process is busy swapping pages in and out, instead of doing useful work.</li></ul></li></ul></li></ul><blockquote><p>[!question]+ Solutions to thrashing</p><ol><li>Decrease the degree of multiprogramming</li><li>Establish “acceptable” page-fault frequency (PFF) rate and use local replacement policy</li><li>Install enough physical memory (hardware)</li><li>Install faster hard disk</li></ol></blockquote><h3 id="page-fault-frequency" tabindex="-1">Page Fault Frequency <a class="header-anchor" href="#page-fault-frequency" aria-label="Permalink to &quot;Page Fault Frequency&quot;">​</a></h3><ul><li>If actual rate too low, process loses frame (we think too many frames assigned, remove some frames)</li><li>If actual rate too high, process gains frame</li></ul><h2 id="allocating-kernel-memory" tabindex="-1">Allocating Kernel Memory <a class="header-anchor" href="#allocating-kernel-memory" aria-label="Permalink to &quot;Allocating Kernel Memory&quot;">​</a></h2><ul><li>Allocating memory for Kernel is different from the allocation of memory for user applications</li><li>Special features of kernel <ul><li>Kernel requests memory for structures of varying sizes <ul><li>Structure for PCB</li><li>Structure for file descriptor</li></ul></li><li>There are multiples instances for each structure <ul><li>there is a PCB for each process</li></ul></li><li>Memory needs to be contiguous</li></ul></li></ul><h3 id="buddy-system" tabindex="-1">Buddy system <a class="header-anchor" href="#buddy-system" aria-label="Permalink to &quot;Buddy system&quot;">​</a></h3><ul><li>Allocates memory from fixed-size segment consisting of physically contiguous pages</li><li>Power-of-2 allocator: memory allocated in units is sized as power of2, one smallest but bigger than requested size</li></ul><p>Advantage:</p><ul><li>Unused chunks can be merged to a bigger one</li></ul><h3 id="slab-allocator" tabindex="-1">Slab allocator <a class="header-anchor" href="#slab-allocator" aria-label="Permalink to &quot;Slab allocator&quot;">​</a></h3><ul><li>A cache <ul><li>is used for unique kernel data structure</li><li>consists of one or more slabs</li><li>A slab is one or more physically contiguous pages <ul><li>Filled with same kind of objects – instantiations of the data structure,</li><li>Each object has two status: free and used</li></ul></li></ul></li><li>If slab is full of used objects, next object is allocated from empty slab <ul><li>If no empty slabs, new slab allocated</li></ul></li></ul>',81)])])}const p=a(o,[["render",r]]);export{m as __pageData,p as default};
//# sourceMappingURL=posts_Operating System_Lecture_08-Virtual Memory.md.fGPhyHvQ.js.map

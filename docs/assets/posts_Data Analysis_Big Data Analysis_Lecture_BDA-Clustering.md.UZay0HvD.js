import{_ as a,c as r,a5 as e,j as l,a as i,o as s}from"./chunks/framework.CHhwEXkI.js";const m=JSON.parse('{"title":"BFR","description":"Please describe how the K-Means algorithm can be extended to detect outliers. Use a simple example to support your answer.","frontmatter":{"date":"2024-11-22T00:00:00.000Z","title":"BFR","status":"DONE","author":["AllenYGY"],"tags":["NOTE","BFR","K-Means"],"description":"Please describe how the K-Means algorithm can be extended to detect outliers. Use a simple example to support your answer.","publish":true},"headers":[],"relativePath":"posts/Data Analysis/Big Data Analysis/Lecture/BDA-Clustering.md","filePath":"posts/Data Analysis/Big Data Analysis/Lecture/BDA-Clustering.md","lastUpdated":null}'),o={name:"posts/Data Analysis/Big Data Analysis/Lecture/BDA-Clustering.md"};function n(u,t,h,d,c,g){return s(),r("div",null,t[0]||(t[0]=[e('<h1 id="bfr-algorithm" tabindex="-1">BFR Algorithm <a class="header-anchor" href="#bfr-algorithm" aria-label="Permalink to &quot;BFR Algorithm&quot;">​</a></h1><p>The <strong>BFR Algorithm</strong> is an extension of K-Means designed for large-scale and high-dimensional data. It improves K-Means by dividing data into three sets:</p><ol><li><em>Discard Set (DS):</em> Summarizes points close to cluster centroids using statistics (e.g., count, sum, sum of squares).</li><li><em>Compression Set (CS):</em> Groups points that form small clusters but aren’t close to the main centroids.</li><li><em>Retained Set (RS):</em> Holds points far from any cluster or mini-cluster, which are potential outliers.</li></ol><h2 id="outlier-detection-process" tabindex="-1">Outlier Detection Process <a class="header-anchor" href="#outlier-detection-process" aria-label="Permalink to &quot;Outlier Detection Process&quot;">​</a></h2><p>Outliers are identified using the RS:</p><ol><li>Points in the RS are compared against cluster centroids.</li><li>Those consistently far from all clusters and mini-clusters across iterations are marked as outliers.</li></ol><h2 id="example" tabindex="-1">Example <a class="header-anchor" href="#example" aria-label="Permalink to &quot;Example&quot;">​</a></h2><p>A 2D dataset shows customer transactions. Most points group into three clusters:</p><ul><li>Frequent, low-value purchases.</li><li>Occasional, high-value purchases.</li><li>Moderate frequency and value.</li></ul><p>Some points are far from these groups.</p><ol><li>Assign points to clusters based on proximity to centroids.</li><li>Points far from all centroids go into the RS.</li><li>After several iterations, points still in the RS are flagged as outliers.</li></ol><p>Unusual transactions, such as very high-value but rare purchases, are identified as outliers.</p><h2 id="bfr-算法-bradley-fayyad-reina-algorithm" tabindex="-1"><strong>BFR 算法（Bradley-Fayyad-Reina Algorithm）</strong> <a class="header-anchor" href="#bfr-算法-bradley-fayyad-reina-algorithm" aria-label="Permalink to &quot;**BFR 算法（Bradley-Fayyad-Reina Algorithm）**&quot;">​</a></h2><p>BFR 算法是一种用于 <strong>大规模数据聚类</strong> 的经典方法，尤其适用于需要在<strong>主内存受限</strong>的情况下处理<strong>高维数据流</strong>。该算法以 <strong>k-means</strong> 为核心，利用主内存和磁盘协作来进行聚类。</p><hr><h3 id="_1-背景与目标" tabindex="-1"><strong>1. 背景与目标</strong> <a class="header-anchor" href="#_1-背景与目标" aria-label="Permalink to &quot;**1. 背景与目标**&quot;">​</a></h3><ul><li><p><strong>背景</strong>：</p><ul><li>数据规模过大，无法一次性加载到主内存中。</li><li>数据分布在高维空间，传统聚类算法在处理速度和内存使用上表现不佳。</li></ul></li><li><p><strong>目标</strong>：</p><ul><li>聚类数据为 kk 个簇，同时高效利用内存和磁盘。</li></ul></li></ul><hr><h3 id="_2-核心思想" tabindex="-1"><strong>2. 核心思想</strong> <a class="header-anchor" href="#_2-核心思想" aria-label="Permalink to &quot;**2. 核心思想**&quot;">​</a></h3><ol><li><p><strong>利用统计摘要</strong>：</p><ul><li>使用 <strong>统计量</strong> 来描述每个聚类簇（例如：质心、协方差矩阵）。</li><li>通过统计摘要避免频繁存储和读取完整数据点，减少内存压力。</li></ul></li><li><p><strong>分块处理数据</strong>：</p><ul><li>数据流按块（chunks）加载到内存，每次只处理一部分数据。</li></ul></li><li><p><strong>聚类更新</strong>：</p><ul><li>对内存中的数据点进行聚类，更新现有的簇统计量。</li><li>对离群点（outliers）单独处理，避免影响聚类质量。</li></ul></li></ol><hr><h3 id="_3-主要步骤" tabindex="-1"><strong>3. 主要步骤</strong> <a class="header-anchor" href="#_3-主要步骤" aria-label="Permalink to &quot;**3. 主要步骤**&quot;">​</a></h3><p>BFR 算法分为以下几个阶段：</p><h4 id="_1-初始化" tabindex="-1"><strong>(1) 初始化</strong> <a class="header-anchor" href="#_1-初始化" aria-label="Permalink to &quot;**(1) 初始化**&quot;">​</a></h4><ul><li>从初始数据中随机采样 kk 个点，使用传统 k-means 算法初始化 kk 个聚类中心。</li><li>记录每个簇的统计摘要： <ul><li>NiN_i：簇 ii 中数据点的数量。</li><li>SUMi\\textbf{SUM}_i：簇 ii 中所有数据点的向量和。</li><li>SUMSQi\\textbf{SUMSQ}_i：簇 ii 中所有数据点的向量平方和。</li></ul></li></ul><h4 id="_2-数据分块处理" tabindex="-1"><strong>(2) 数据分块处理</strong> <a class="header-anchor" href="#_2-数据分块处理" aria-label="Permalink to &quot;**(2) 数据分块处理**&quot;">​</a></h4><p>对于每个加载到内存中的数据块，执行以下操作：</p>',27),l("ol",null,[l("li",null,[l("p",null,[l("strong",null,"分配数据点到簇"),i("：")]),l("ul",null,[l("li",null,"计算每个数据点到所有聚类中心的距离，分配到距离最近的簇。"),l("li",null,[i("更新统计摘要： "),l("ul",null,[l("li",null,"Ni=Ni+1N_i = N_i + 1"),l("li",{x:""},"SUMi=SUMi+x\\textbf{SUM}_i = \\textbf{SUM}_i + \\textbf"),l("li",null,"SUMSQi=SUMSQi+x2\\textbf{SUMSQ}_i = \\textbf{SUMSQ}_i + \\textbf{x}^2")])]),l("li",null,"不保存具体的数据点，仅更新统计量。")])]),l("li",null,[l("p",null,[l("strong",null,"处理离群点"),i("：")]),l("ul",null,[l("li",null,"如果某些数据点距离任何簇中心都较远，标记为离群点（Outliers）。"),l("li",null,"将离群点单独存储，稍后处理。")])])],-1),l("h4",{id:"_3-聚类统计更新",tabindex:"-1"},[l("strong",null,"(3) 聚类统计更新"),i(),l("a",{class:"header-anchor",href:"#_3-聚类统计更新","aria-label":'Permalink to "**(3) 聚类统计更新**"'},"​")],-1),l("ul",null,[l("li",null,[i("使用更新后的统计摘要重新计算每个簇的质心和协方差： "),l("ul",null,[l("li",{N_i:""},"质心：μi=SUMiNi\\mu_i = \\frac{\\textbf{SUM}_i}"),l("li",null,"协方差矩阵：根据 SUMSQi\\textbf{SUMSQ}_i、SUMi\\textbf{SUM}_i 和 NiN_i 计算。")])])],-1),e('<h4 id="_4-合并离群点" tabindex="-1"><strong>(4) 合并离群点</strong> <a class="header-anchor" href="#_4-合并离群点" aria-label="Permalink to &quot;**(4) 合并离群点**&quot;">​</a></h4><ul><li>检查离群点集合，如果某些离群点在新一轮聚类中接近某个簇的质心，则将其合并到该簇中。</li><li>如果离群点长期不属于任何簇，可将其删除或作为单独簇处理。</li></ul><h4 id="_5-重复迭代" tabindex="-1"><strong>(5) 重复迭代</strong> <a class="header-anchor" href="#_5-重复迭代" aria-label="Permalink to &quot;**(5) 重复迭代**&quot;">​</a></h4><ul><li>加载下一个数据块，重复步骤 (2)-(4)，直到所有数据处理完毕。</li></ul><hr><h3 id="_4-算法特点" tabindex="-1"><strong>4. 算法特点</strong> <a class="header-anchor" href="#_4-算法特点" aria-label="Permalink to &quot;**4. 算法特点**&quot;">​</a></h3><ul><li><p><strong>优点</strong>：</p><ul><li><strong>节省内存</strong>：通过统计摘要处理数据，无需存储所有点。</li><li><strong>适合高维数据</strong>：避免直接对高维数据计算，减少计算复杂度。</li><li><strong>增量更新</strong>：能够动态处理数据流，适应不断到来的新数据。</li></ul></li><li><p><strong>缺点</strong>：</p><ul><li>对于复杂分布的簇，可能不能很好地捕捉非球形簇的特征。</li><li>离群点处理的质量依赖于算法参数（如阈值）。</li></ul></li></ul><hr><h3 id="_5-应用场景" tabindex="-1"><strong>5. 应用场景</strong> <a class="header-anchor" href="#_5-应用场景" aria-label="Permalink to &quot;**5. 应用场景**&quot;">​</a></h3><ul><li><strong>大规模数据聚类</strong>： <ul><li>大型社交网络数据分析。</li><li>电商中的推荐系统。</li></ul></li><li><strong>高维数据分析</strong>： <ul><li>文本数据的主题分类。</li><li>生物信息学中的基因表达聚类。</li></ul></li><li><strong>实时数据处理</strong>： <ul><li>网络流量聚类。</li><li>日志数据中的模式发现。</li></ul></li></ul><hr><h3 id="总结" tabindex="-1"><strong>总结</strong> <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;**总结**&quot;">​</a></h3><p>BFR 算法是一种结合了 k-means 和统计摘要的高效聚类算法，适用于大规模、高维、数据流式的场景。通过分块处理和离群点管理，它能够在内存限制下实现接近于传统聚类算法的效果。如果需要实现或更深入的细节，欢迎随时交流！</p>',13)]))}const f=a(o,[["render",n]]);export{m as __pageData,f as default};
